---
title: "100-wgs-download"
output: html_document
date: "2023-06-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

```{r}
library(tidyverse)
```

## https://www.ncbi.nlm.nih.gov/bioproject/PRJNA311498

```{r}
sra<-read_csv("meta/lates-wgs-SraRunInfo.csv")
sra %>% select(download_path)
```

Doing this a lazy way.    

in data/raw

```{sh, eval=FALSE}
cat ../../meta/lates-wgs-SraRunInfo.csv | cut -d ',' -f 10 | while read line; do wget $line; done;
```

Need to dump files, something like

fastq-dump --outdir split --skip-technical--readids --read-filter pass --dumpbase --split-3 --gzip --clip 

module load ncbi-toolkit/26_0_1 (added to bash_profile)     
module load sratoolkit/3.0.0       

fastq-dump --outdir split --skip-technical --readids --read-filter pass --dumpbase --split-3 --gzip --clip raw/SRR3165618.sralite.1      

--readids causes bwa to not like it, dropping option
 `for f in raw/*sralite.1; do echo $f; fastq-dump --outdir split --skip-technical --read-filter pass --dumpbase --split-3 --gzip --clip $f; done;  `    

This is going to take a day or so. Next time do something faster!    

Produces files like: 
SRR3165618.sralite.1_pass_1.fastq.gz      
SRR3165618.sralite.1_pass_2.fastq.gz     

can use doAlign-zipped.sh to align which will give us properly paired and PCR deduplicated read counts. Should probably consider per-site coverage calcs. Adding to doAlign-zipped.sh .      

samtools depth -a $name.bam | awk '{sum+="\$3"} END {print sum/NR}' 

Note to self: Trial on an reduced set of files

`(base) maccamp@farm:~/lates-wgs/data/split$ gunzip -c SRR3165592.sralite.1_pass_1.fastq.gz | head -n 400000 > test.sralite.1_pass_1.fastq`      
`(base) maccamp@farm:~/lates-wgs/data/split$ gunzip -c SRR3165592.sralite.1_pass_2.fastq.gz | head -n 400000 > test.sralite.1_pass_2.fastq`      

` gzip test.sralite.1_pass_*`    
`maccamp@farm:~/lates-wgs/data/split$ bash ../../doAlign-zipped.sh test.txt /home/maccamp/lates-wgs/genome/GCF_001640805.2_TLL_Latcal_v3_genomic.fna.gz`      

Ran to completion:   
test-fastqs,200663,97850,0.0151149    

`(base) maccamp@farm:~/lates-wgs/data/split$ ls | grep pass_1 | perl -pe 's/.fastq.gz//g' > forward`     
`(base) maccamp@farm:~/lates-wgs/data/split$ ls | grep pass_2 | perl -pe 's/.fastq.gz//g' > reverse`     
`(base) maccamp@farm:~/lates-wgs/data/split$ ls | grep pass_2 | perl -pe 's/.sralite.1_pass_2.fastq.gz//g' > name`      

(running for 4-10)      
`(base) maccamp@farm:~/lates-wgs/data/split$ paste forward reverse name  > to-align.txt`     
`bash ../../doAlign-zipped.sh to-align.txt /home/maccamp/lates-wgs/genome/GCF_001640805.2_TLL_Latcal_v3_genomic.fna.gz `

Cluster choked. Checking available partitions:

sacctmgr show User $USER --associations
sinfo shows time limits     

bmm is available 150-00:00
## QC     
     
First, get meta.    

```{r}
meta<-sra %>% select(Run, BioSample, Sample, Region, Locality)
meta$Region<-factor(meta$Region, levels=c("Queensland","Northern Territory","Papua New Guinea",
                                              "Indonesia","Philipines","Vietnam","Cambodia","Thailand",
                                              "India Eastern Coast","India Western Coast"))
meta %>% group_by(Region, Locality) %>% summarize(Count=n())
```
     
Visualize read counts.        

Set up bamlist, maybe downsample

Check one region with GLs
